name: scheduled-scrape

on:
  schedule:
    - cron: '0 6 * * *'
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Write Google credentials
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}
        run: |
          echo "$GOOGLE_CREDENTIALS" > credentials.json

      - name: Run scraper
        env:
          SHEET_ID: ${{ secrets.SHEET_ID }}
        run: |
          python - <<'PY'
          import os, yaml, sys
          cfg_path = "config.yaml"
          try:
              with open(cfg_path) as f:
                  cfg = yaml.safe_load(f) or {}
          except FileNotFoundError:
              cfg = {}

          sheet = os.environ.get("SHEET_ID")
          if sheet:
              cfg['sheet_id'] = sheet
              with open(cfg_path, "w") as f:
                  f.write(yaml.dump(cfg))
              print("patched config with SHEET_ID")
          else:
              print("SHEET_ID not provided; skipping patch")

          PY

          python scrape_and_push.py
